{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo:  ECAS/Ophidia simple commands examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all import PyOphidia modules and connect to server (connection details are inferred from the ECAS environment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from PyOphidia import cube, client\n",
    "cube.Cube.setclient(read_env=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a datacube from the NetCDF file:\n",
    "- The file is **/data/tasmax_day_CMCC-CESM_rcp85_r1i1p1_20960101-21001231.nc**\n",
    "- The variable to be imported is **tasmax**\n",
    "- Data should be arranged in order to operate on time series (**time** dimension) \n",
    "\n",
    "**Note: We are not directly reading the file from the Notebook**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycube = cube.Cube.importnc(\n",
    "                src_path='/data/tasmax_day_CMCC-CESM_rcp85_r1i1p1_20960101-21001231.nc',\n",
    "                measure='tasmax',\n",
    "                imp_dim='time',\n",
    "                ncores=2,\n",
    "                description=\"Imported cube\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the datacubes available in the virtual file system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube.Cube.list(level=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the list of arguments and default values we can use the python *help()* command can be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(cube.Cube.list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the cube and its dimensions structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycube.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subset the datacube over space (lat and lon) and time\n",
    "\n",
    "**Note: each instance method produces a new datacube object**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycube2 = mycube.subset(\n",
    "                subset_dims=\"lat|lon|time\",\n",
    "                subset_filter=\"-50:20|20:160|150:240\",\n",
    "                subset_type=\"coord\",\n",
    "                ncores=2,\n",
    "                description=\"Subsetted cube\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the new cube; dimensions have been changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycube2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what does the datacube actually contain at this point? We can use the explore method to check the content. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycube2.explore(limit_filter=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then compute the maximum value over the time series for each point in the spatial domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycube3 = mycube2.reduce(\n",
    "                    operation='max',\n",
    "                    ncores=2,\n",
    "                    description=\"Reduced cube\"\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the new cube the time dimension is be \"collapesed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycube3.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now reorganize the data structure by making the longitude dimension an array-oriented dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycube4 = mycube3.rollup(\n",
    "                    ncores=2,\n",
    "                    description=\"Rollup cube\"\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new cube will now have *lon* has an array-dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycube4.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each operation executed creates a new datacube on the framework (datacubes are not overwritten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube.Cube.list(level=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's export the data into a Python-friendly structure. \n",
    "\n",
    "**Note: this is the first time we move data from the server-side to the Notebook**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The structure looks something like this\n",
    "\n",
    "<img src=\"imgs/export_array.png\" alt=\"Export Array\" width=\"800\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = mycube4.export_array()\n",
    "\n",
    "from IPython.lib.pretty import pprint\n",
    "pprint(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data exported in the Python structure can be used to create a map (note the definition of a Python function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "def plotData(data):\n",
    "    \n",
    "    import cartopy.crs as ccrs\n",
    "    import matplotlib.pyplot as plt\n",
    "    from cartopy.mpl.geoaxes import GeoAxes\n",
    "    from cartopy.util import add_cyclic_point\n",
    "    import numpy as np\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "    fig = plt.figure(figsize=(12, 6), dpi=100)\n",
    "\n",
    "    #Add Geo axes to the figure with the specified projection (PlateCarree)\n",
    "    projection = ccrs.PlateCarree()\n",
    "    ax = plt.axes(projection=projection)\n",
    "\n",
    "    #Draw coastline and gridlines\n",
    "    ax.coastlines()\n",
    "\n",
    "    gl = ax.gridlines(crs=projection, draw_labels=True, linewidth=1, color='black', alpha=0.9, linestyle=':')\n",
    "    gl.xlabels_top = False\n",
    "    gl.ylabels_right = False\n",
    "\n",
    "    lat = data['dimension'][0]['values'][ : ]\n",
    "    lon = data['dimension'][1]['values'][ : ]\n",
    "    var = data['measure'][0]['values'][ : ]\n",
    "    var = np.reshape(var, (len(lat), len(lon)))\n",
    "\n",
    "    #Wraparound points in longitude\n",
    "    var_cyclic, lon_cyclic = add_cyclic_point(var, coord=np.asarray(lon))\n",
    "    x, y = np.meshgrid(lon_cyclic,lat)\n",
    "\n",
    "    #Define color levels for color bar\n",
    "    clevs = np.arange(200,340,5)\n",
    "\n",
    "    #Set filled contour plot\n",
    "    cnplot = ax.contourf(x, y, var_cyclic, clevs, transform=projection,cmap=plt.cm.jet)\n",
    "    plt.colorbar(cnplot,ax=ax)\n",
    "\n",
    "    ax.set_aspect('auto', adjustable=None)\n",
    "\n",
    "    plt.title('Maximum Near-Surface Air Temperature (deg K)')\n",
    "    plt.show()\n",
    "    \n",
    "plotData(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What If we want to consider the whole spatial domain and specify a subset only on the time range? \n",
    "\n",
    "We can perform the new set of operations on *mycube* object, without the need to re-import the dataset from the file. Note that we are providing the time range in human-readable form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newMycube2 = mycube.subset(\n",
    "                subset_dims=\"time\",\n",
    "                subset_filter=\"2096-01-01_2096-12-31\",\n",
    "                subset_type=\"coord\",\n",
    "                time_filter=\"yes\",\n",
    "                ncores=2,\n",
    "                description=\"New subsetted cube\"\n",
    "        )\n",
    "\n",
    "newMycube2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can the rerun the same operations on the new cube ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newMycube3 = newMycube2.reduce(\n",
    "                    operation='max',\n",
    "                    ncores=2,\n",
    "                    description=\"New reduced cube\"\n",
    "                )\n",
    "\n",
    "newMycube4 = newMycube3.rollup(\n",
    "                    ncores=2,\n",
    "                    description=\"New rollup cube\"\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and plot the new datacube values on a map using the function *plotData*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = newMycube4.export_array()\n",
    "plotData(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What if we want to get the *minimum* instead of the maximum value?\n",
    "\n",
    "Again we can perform the new set of operations on *newMycube2* object, without the need to re-import or subset the dataset again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newNewMycube3 = newMycube2.reduce(\n",
    "                    operation='min',\n",
    "                    ncores=2,\n",
    "                    description=\"New reduced cube2\"\n",
    "                )\n",
    "\n",
    "newNewMycube4 = newNewMycube3.rollup(\n",
    "                    ncores=2,\n",
    "                    description=\"New rollup cube2\"\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and plot the new datacube values on a map using the function *plotData*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = newNewMycube4.export_array()\n",
    "plotData(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our workspace now contains several datacubes from the experiments just run. Once done, we can clear the space before moving to other notebooks. \n",
    "\n",
    "**Note: the *client.submit* is exploiting the underlying *PyOphidia client class* to submit commands in terminal-like syntax.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube.Cube.deletecontainer(container='tasmax_day_CMCC-CESM_rcp85_r1i1p1_20960101-21001231.nc',force='yes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The virtual file system should now be \"clean\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube.Cube.list(level=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
