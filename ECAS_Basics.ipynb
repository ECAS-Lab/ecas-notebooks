{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo:  ECAS/Ophidia simple commands examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all import PyOphidia modules and connect to server (connection details are inferred from the ECAS environment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from PyOphidia import cube, client\n",
    "cube.Cube.setclient(read_env=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a datacube from the NetCDF file:\n",
    "- The file is **/data/ecas_training/tos.nc**\n",
    "- The variable to be imported is **tos**\n",
    "- Data should be arranged in order to operate on time series (**time** dimension) \n",
    "\n",
    "**Note: We are not directly reading the file from the Notebook**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mycube = cube.Cube.importnc(\n",
    "                src_path='/data/ecas_training/tos.nc',\n",
    "                measure='tos',\n",
    "                imp_dim='time',\n",
    "                ioserver='ophidiaio_memory',\n",
    "                ncores=2,\n",
    "                description=\"Imported cube\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the datacubes available in the virtual file system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube.Cube.list(level=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the list of arguments and default values we can use the python *help()* command can be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(cube.Cube.list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the cube and its dimensions structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycube.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subset the datacube over space (lat and lon) and time\n",
    "\n",
    "**Note: each instance method produces a new datacube object**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mycube2 = mycube.subset(\n",
    "                subset_dims=\"lat|lon|time\",\n",
    "                subset_filter=\"-80:30|30:120|151:240\",\n",
    "                subset_type=\"coord\",\n",
    "                ncores=2,\n",
    "                description=\"Subsetted cube\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the new cube; dimensions have been changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycube2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what does the datacube actually contain at this point? We can use the explore method to check the content. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycube2.explore(limit_filter=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then compute the maximum value over the time series for each point in the spatial domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mycube3 = mycube2.reduce(\n",
    "                    operation='max',\n",
    "                    ncores=2,\n",
    "                    description=\"Reduced cube\"\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the new cube the time dimension is be \"collapesed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycube3.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now reorganize the data structure by making the longitude dimension an array-oriented dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mycube4 = mycube3.rollup(\n",
    "                    ncores=2,\n",
    "                    description=\"Rollup cube\"\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new cube will now have *lon* has an array-dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycube4.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each operation executed creates a new datacube on the framework (datacubes are not overwritten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube.Cube.list(level=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's export the data into a Python-friendly structure. \n",
    "\n",
    "**Note: this is the first time we move data from the server-side to the Notebook**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The structure looks something like this\n",
    "\n",
    "<img src=\"imgs/export_array.png\" alt=\"Export Array\" width=\"800\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = mycube4.export_array()\n",
    "\n",
    "from IPython.lib.pretty import pprint\n",
    "pprint(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data exported in the Python structure can be used to create a map (note the definition of a Python function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotData(data):\n",
    "    import matplotlib.pyplot as plt\n",
    "    from mpl_toolkits.basemap import Basemap, cm\n",
    "    import numpy as np\n",
    "\n",
    "    lat = data['dimension'][0]['values'][:]\n",
    "    lon = data['dimension'][1]['values'][:]\n",
    "    var = data['measure'][0]['values'][:]\n",
    "\n",
    "    fig = plt.figure(figsize=(15, 15), dpi=100)\n",
    "    ax  = fig.add_axes([0.1,0.1,0.8,0.8])\n",
    "\n",
    "    map = Basemap(projection='cyl',llcrnrlat= -90,urcrnrlat= 90, llcrnrlon=0,urcrnrlon=360, resolution='c')\n",
    "\n",
    "    map.drawcoastlines()\n",
    "    map.drawparallels(np.arange( -90, 90,30),labels=[1,0,0,0])\n",
    "    map.drawmeridians(np.arange(-180,180,30),labels=[0,0,0,1])\n",
    "\n",
    "    x, y = map(*np.meshgrid(lon,lat))\n",
    "\n",
    "    cnplot = map.contourf(x,y,var,np.arange(270,305,0.5),cmap=plt.cm.jet)\n",
    "    cbar = map.colorbar(cnplot,location='right',format='%.2f')\n",
    "\n",
    "    plt.title('Sea Surface Temperature (deg K)')\n",
    "    plt.show()\n",
    "    \n",
    "plotData(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What If we want to consider the whole spatial domain and specify a subset only on the time range? \n",
    "\n",
    "We can perform the new set of operations on *mycube* object, without the need to re-import the dataset from the file. Note that we are providing the time range in human-readable form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newMycube2 = mycube.subset(\n",
    "                subset_dims=\"time\",\n",
    "                subset_filter=\"2001-01-01_2001-12-31\",\n",
    "                subset_type=\"coord\",\n",
    "                time_filter=\"yes\",\n",
    "                ncores=2,\n",
    "                description=\"New subsetted cube\"\n",
    "        )\n",
    "\n",
    "newMycube2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can the rerun the same operations on the new cube ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newMycube3 = newMycube2.reduce(\n",
    "                    operation='max',\n",
    "                    ncores=2,\n",
    "                    description=\"New reduced cube\"\n",
    "                )\n",
    "\n",
    "newMycube4 = newMycube3.rollup(\n",
    "                    ncores=2,\n",
    "                    description=\"New rollup cube\"\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and plot the new datacube values on a map using the function *plotData*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = newMycube4.export_array()\n",
    "plotData(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What if we want to get the *minimum* instead of the maximum value?\n",
    "\n",
    "Again we can perform the new set of operations on *newMycube2* object, without the need to re-import or subset the dataset again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newNewMycube3 = newMycube2.reduce(\n",
    "                    operation='min',\n",
    "                    ncores=2,\n",
    "                    description=\"New reduced cube2\"\n",
    "                )\n",
    "\n",
    "newNewMycube4 = newNewMycube3.rollup(\n",
    "                    ncores=2,\n",
    "                    description=\"New rollup cube2\"\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and plot the new datacube values on a map using the function *plotData*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = newNewMycube4.export_array()\n",
    "plotData(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our workspace now contains several datacubes from the experiments just run. Once done, we can clear the space before moving to other notebooks. \n",
    "\n",
    "**Note: the *client.submit* is exploiting the underlying *PyOphidia client class* to submit commands in terminal-like syntax.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cube.Cube.client.submit(\"oph_delete cube=[container=tos.nc]\")\n",
    "cube.Cube.deletecontainer(container='tos.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The virtual file system should now be \"clean\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cube.Cube.list(level=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
